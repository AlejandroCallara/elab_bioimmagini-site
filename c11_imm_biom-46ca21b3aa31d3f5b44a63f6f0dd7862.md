
# Capitolo 1: Modello dell'immagine biomedica e misure di qualità
## Dal Post-processing all'analisi dell'immagine

Nell'imaging biomedico, storicamente le immagini vengono prodotte dal dispositivo di acquisizione avendo come obiettivo l'analisi visiva da parte del radiologo o medico esperto. L'analisi visiva viene effettuata tradizionalmente attraverso la stampa radiografica e la visualizzazione su diafanoscopio. Oggi più comunemente le immagini vengono visualizzate su schermo, sia per ragioni di costo (la stampa radiografica è estremamente costosa) che di praticità (un moderno esame TAC o MRI può contenere centinaia di immagini). L'analisi visiva da parte dell'operatore esperto conduce alla compilazione di un referto diagnostico. L'analisi visiva è intrinsecamente qualitativa, cioè di tipo descrittivo. Nell'ipotesi di un referto relativo ad un esame MRI cardiovascolare, descrizioni di tipo qualitativo potranno essere del tipo “Ventricolo sinistro di normali dimensioni”, “Funzione cardiaca ridotta”, etc. In realtà nella pratica radiologica viene adottato un criterio semi-quantitativo, secondo il quale i vari livelli di una patologia vengono identificati per classi (ad esempio severo, medio, moderato, lieve, assente). Al medico refertante viene richiesto di associare quanto visualizzato dall'immagine diagnostica ad una classe di patologia. Troveremo quindi nel referto espressioni del tipo “buona cinesi segmentaria”, “severo accumulo di ferro”, etc. Dove le locuzioni “buona”, “severo” non indicano un giudizio puramente qualitativo, ma la classificazione semi-quantitativa su di una opportuna scala. L'analisi qualitativa e semi-quantitativa non richiedono in generale l'uso di algoritmi di elaborazione dell'immagine, se si esclude il possibile uso di algoritmi di filtraggio che hanno lo scopo di ottimizzare la visione dell'immagine stessa. 
 
Il passaggio ad un referto di tipo quantitativo comporta invece l'utilizzo di algoritmi di elaborazione atti a estrarre dall'immagine degli indici numerici e quindi quantitativi. Ad esempio l'uso di un programma di segmentazione delle cavità ventricolari permetterà di ottenere una misura quantitativa dei volumi ventricolari destro e sinistro, misure che potranno essere riportate a referto, ad esempio come: “VTD 66 ml/m2”, dove il Volume Telediastolico è riportato in ml normalizzato alla superficie corporea in m2. I vantaggi di una misura di tipo quantitativo sono la superiore oggettività rispetto all'analisi qualitativa o semi-quantitativa e la maggior precisione rispetto ad un sistema discreto a classi. Notiamo comunque che tipicamente nel referto la classificazione a classi viene comunque conservata, cioè le informazioni quantitative vengono “tradotte” in classi di gravità della patologia. Questo ha lo scopo di rendere il referto più immediatamente comprensibile dal medico richiedente il referto stesso che non è in generale esperto della particolare metodica di imaging utilizzata e ha quindi bisogno della traduzione dell'indice qualitativo in una classe di merito a lui nota. Le soglie di conversione vengono solitamente definite all'interno di linee guida sviluppate dalle varie società scientifiche. In Figura 1.1 è riportato un esempio di referto da immagini MRI.      

<img src="./images/image.png" alt="Esempio di referto radiologico" style="width:100%;">

*Figura 1.1. Esempio di referto radiologico (MRI cardiaca per lo studio dell'accumulo di ferro).*

A questo livello l'analisi visiva e l'elaborazione dell'immagine vengono effettuate in parallelo, quindi gli stessi insiemi di immagini vengono valutate visivamente ed elaborate al calcolatore. Nella pratica clinica odierna, tuttavia, iniziano ad essere utilizzate procedure di acquisizione destinate a produrre immagini inutili dal punto di vista dell'esame visivo e destinate in modo univoco all'elaborazione. Esempi tipici sono le immagini PC (Phase Contrast) in risonanza per la valutazione algoritmica della velocità di flusso e le immagini T1/T2/T2* multiecho per la caratterizzazione quantitativa dei tessuti in MR. In questi casi la parte di elaborazione cessa di essere un “add-on” del processo diagnostico, e ne diviene parte integrante e insostituibile. Nell'esempio di referto in figura troviamo un esempio di questo tipo nella definizione dell'accumulo di ferro attraverso la misura quantitativa del valore di T2* sul miocardio e sul parenchima del fegato. In questo caso il referto è puramente quantitativo, nel senso che l’analisi visiva non è rilevante. Nella terminologia moderna il termine “elaborazione delle bioimmagini” viene preferibilmente sostituito con il termine “analisi dell'immagine medica” (medical image analysis), proprio per sottolineare la preminenza dell’analisi software su quella visuale. 

È importante notare come in questo caso l’elaborazione dell’immagine biomedica da “ausilio al processo diagnostico” diviene “parte strutturale del processo diagnostico” e l’affidabilità del processo di elaborazione deve essere equivalente a quella di un dispositivo medico vero e proprio. Il decreto legislativo 37 del 25/01/2010 recepisce in Italia la direttiva europea 93/42/CEE sulla certificazione dei dispositivi medici, chiarendo che il software che implementa algoritmi di elaborazione di immagini se usato a fini diagnostici è da considerare un “dispositivo medico” e come tale richiede una opportuna certificazione. Sostanzialmente il software per l’analisi dell’immagine biomedica è equiparato ad un dispositivo di acquisizione o altro strumento diagnostico. 
Secondo la normativa, un Dispositivo Medico è definito come “qualunque strumento, apparecchio, impianto, software, sostanza o altro prodotto utilizzato da solo o in combinazione, compreso il software destinato dal fabbricante ad essere impiegato specificatamente con finalità diagnostiche e/o terapeutiche….”, quindi possono essere individuate quattro tipologie di software, che comprendono sia software “stand-alone”, cioè software utilizzati in modo autonomo, che software integrati in altri dispositivi medici che concorrono al funzionamento dei dispositivi stessi. Ad esempio, il software di controllo di una macchina per l’analisi di campioni biologici o di una macchina di acquisizione immagini rappresenta un software integrato, mentre un programma per l’elaborazione di immagini è un software stand-alone.  

A questo livello l'analisi visiva e l'elaborazione dell'immagine vengono effettuate in parallelo, quindi gli stessi insiemi di immagini vengono valutate visivamente ed elaborate al calcolatore. Nella pratica clinica odierna, tuttavia, iniziano ad essere utilizzate procedure di acquisizione destinate a produrre immagini inutili dal punto di vista dell'esame visivo e destinate in modo univoco all'elaborazione. Esempi tipici sono le immagini PC (Phase Contrast) in risonanza per la valutazione algoritmica della velocità di flusso e le immagini T1/T2/T2* multiecho per la caratterizzazione quantitativa dei tessuti in MR. In questi casi la parte di elaborazione cessa di essere un “add-on” del processo diagnostico, e ne diviene parte integrante e insostituibile. Nell'esempio di referto in figura troviamo un esempio di questo tipo nella definizione dell'accumulo di ferro attraverso la misura quantitativa del valore di T2* sul miocardio e sul parenchima del fegato. In questo caso il referto è puramente quantitativo, nel senso che l’analisi visiva non è rilevante. Nella terminologia moderna il termine “elaborazione delle bioimmagini” viene preferibilmente sostituito con il termine “analisi dell'immagine medica” (medical image analysis), proprio per sottolineare la preminenza dell’analisi software su quella visuale. 

È importante notare come in questo caso l’elaborazione dell’immagine biomedica da “ausilio al processo diagnostico” diviene “parte strutturale del processo diagnostico” e l’affidabilità del processo di elaborazione deve essere equivalente a quella di un dispositivo medico vero e proprio. Il decreto legislativo 37 del 25/01/2010 recepisce in Italia la direttiva europea 93/42/CEE sulla certificazione dei dispositivi medici, chiarendo che il software che implementa algoritmi di elaborazione di immagini se usato a fini diagnostici è da considerare un “dispositivo medico” e come tale richiede una opportuna certificazione. Sostanzialmente il software per l’analisi dell’immagine biomedica è equiparato ad un dispositivo di acquisizione o altro strumento diagnostico. 
Secondo la normativa, un Dispositivo Medico è definito come “qualunque strumento, apparecchio, impianto, software, sostanza o altro prodotto utilizzato da solo o in combinazione, compreso il software destinato dal fabbricante ad essere impiegato specificatamente con finalità diagnostiche e/o terapeutiche...”, quindi possono essere individuate quattro tipologie di software, che comprendono sia software “stand-alone”, cioè software utilizzati in modo autonomo, che software integrati in altri dispositivi medici che concorrono al funzionamento dei dispositivi stessi. Ad esempio, il software di controllo di una macchina per l’analisi di campioni biologici o di una macchina di acquisizione immagini rappresenta un software integrato, mentre un programma per l’elaborazione di immagini è un software stand-alone.  

La Figura 1.2 descrive le quattro classi di software utilizzati in ambito biomedicale e soggetti a certificazione. Le procedure di elaborazione dell’immagine ricadono nella terza classe (Software sviluppato per analizzare dati acquisiti da dispositivi medici). 
È importante notare come il software che costituisce una cartella clinica non è un dispositivo medico, in quanto non contribuisce direttamente alla diagnosi e cura. 

<img src="./images/image-1.png" alt="Tipi di software utilizzati in ambito biomedicale" style="width:100%;">

*Figura 1.2. Tipi di software utilizzati in ambito biomedicale.*

## Richiami sulla definizione di Immagine Biomedica
### Livelli di grigio e colormap
Dal punto di vista dell’analisi dell’immagine, una immagine biomedica è una rappresentazione spazio/temporale di un fenomeno fisico legato al dispositivo di acquisizione. Le caratteristiche fisiche di una regione di spazio (voxel) rispetto ad una qualche eccitazione endogena o esogena (opacità ai raggi X, risonanza magnetica, emissione di radiazioni, etc.) vengono tradotti in un valore numerico di segnale. Nella maggior parte dei casi viene misurata una singola quantità, e quindi l’immagine presenta un singolo canale (livello di grigio). Il livello di grigio è proporzionale al fenomeno fisico misurato. Oggi sostanzialmente tutte le immagini biomediche sono immagini digitali (quindi sono espresse in forma numerica come matrici di numeri interi). Esiste uno standard di fatto di codifica che è il formato DICOM come verrà dettagliato nel seguito.
Vale la pena di notare che tra le normali immagini digitali (Figura 1.3) e le immagini biomediche (Figura 1.4) esistono alcune fondamentali differenze.

Un immagine digitale è tipicamente a colori, quindi è rappresentata come un array (3,dx,dy), cioè attraverso tre canali tipicamente in formato RGB (Red, Green, Blue). I tre canali possono tipicamente assumere valori tra 0 e 255. Quindi una immagine digitale di dimensioni (dx,dy) non compressa occupa 3dxdy byte più alcuni byte di header, cioè di intestazione dell’immagine.

<img src="./images/image-2.png" alt="Esempio di immagine a colori" style="width:100%;">

*Figura 1.3. Concetto di immagine a colori (RGB).*

Una immagine biomedica può essere invece vista come una immagine a livelli di grigio a singolo canale che può essere caratterizzata dal suo istogramma. Tipicamente i livelli di grigio possono essere più di 255, spesso l’immagine è codificata a 12 bit (212=4096) o a 16 bit (216=65536) nel caso di immagini a valori solo positivi. Se sono codificati valori negativi i valori possibili variano di conseguenza.
Nella figura è rappresentata una immagine di risonanza con valori che vanno dallo 0 (nessun segnale, aria) ai valori più alti relativi al grasso. È possibile visualizzare una immagine a livelli di grigio a colori attraverso una opportuna color map, cioè una trasformazione che fa corrispondere ad un certo livello di grigio una terna di valori RGB. Questa tecnica è spesso utilizzata per migliorare la qualità di visualizzazione, ad esempio, in immagini di medicina nucleare (SPECT o PET), sfruttando il fatto che l'occhio umano (o meglio il sistema occhio-cervello) è molto più efficiente nel riconoscimento dei colori rispetto ai livelli di grigio.

<img src="./images/image-3.png" alt="Esempio di immagine biomedica" style="width:100%;">

*Figura 1.4. Concetto di immagine biomedica (MRI assiale dell'addome, MRI Lab, FTGM, Pisa).*

Dalla Figura 1.5 Notiamo che l’immagine a colori a destra non ha alcun senso dal punto di vista diagnostico. Mentre l’immagine a livelli di grigio ci informa del fatto che un tessuto (il grasso) produce un segnale MR maggiore di quello del muscolo e dell’aria, nell’immagine a colori non possiamo sapere se il blu rappresenta un segnale maggiore o minore del giallo.

<img src="./images/image-4.png" alt="Immagine assiale MRI a livello della coscia" style="width:100%;">

*Figura 1.5. Immagine assiale MRI a livello della coscia (MRI Lab, Aarhus, DK) e trasformazione in RGB.*

Per dare un senso medico all’immagine dobbiamo associare all’immagine a colori la color map utilizzata (Figura 1.6).

<img src="./images/image-5.png" alt="Esempio di colormap" style="width:100%;">

*Figura 1.6. Esempio di colormap.*

La color map ci dice che il blu corrisponde a livelli di segnale più basso rispetto al giallo e rende l’immagine utilizzabile in senso diagnostico. L’immagine, quindi, verrà visualizzata come in Figura 1.7.

<img src="./images/image-7.png" alt="Visualizzazione di immagine a falsi colori in radiologia" style="width:100%;">

*Figura 1.7. Visualizzazione corretta di una immagine a falsi colori in radiologia.*

L'immagine con associata la color map utilizzata per la rappresentazione a colori assume quindi una utilità diagnostica, in quanto consente di associare ad un colore l'intensità di segnale acquisita dalla macchina di acquisizione, in questo caso una MRI. Riassumendo:

1. Le immagini biomediche tipicamente vengono visualizzate a livelli di grigio (US, MRI, CT). Il significato del livello di grigio dipende dalla fisica di acquisizione. Il fatto che alcuni software non specifici per l’analisi di immagini biomediche, come il MATLAB, visualizzino di default una immagine a livelli di grigio con una color map arbitraria non autorizza a ritenere che tale rappresentazione sia accettabile.

2. In alcuni casi (SPECT, PET) si utilizzano delle color map standard per visualizzare l’immagine a falsi colori. La color map utilizzata deve essere sempre associata all’immagine. L’immagine a colori risultante è una rappresentazione dell’immagine originale a livelli di grigio come acquisita dalla macchina di acquisizione, che è l’unica fonte reale di informazione diagnostica. Come si vedrà in seguito il formato standard di memorizzazione delle immagini biomediche consente il salvataggio della color map da utilizzare insieme all’immagine stessa.

3. Il modo “giusto” di rappresentare una immagine dipende sostanzialmente da una convenzione tra gli utilizzatori. Se il mondo radiologico visualizza le immagini MRI a livelli di grigio è il caso di adeguarsi e non inventare rappresentazioni non standard. Non seguire la convenzione implica rendere l'immagine non utile alla comunità di medici che la utilizza e comporta tipicamente il licenziamento dell'Ingegnere Biomedico responsabile. 

## Standard DICOM
Come già accennato le immagini biomediche sono tipicamente memorizzate in formato DICOM. Le immagini DICOM sono le uniche che conservano il valore diagnostico dell’immagine e hanno valore legale. Rappresentazioni dell’immagine DICOM (immagini a colori, salvataggio in formati a minor numero di livelli di grigio  come TIF o JPEG) alterano il contenuto diagnostico dell’immagine e non vanno utilizzati nella distribuzione o immagazzinamento di immagini mediche. 
Un file DICOM contiene tipicamente un header (intestazione) contenente informazioni sull’immagine e l’immagine vera e propria codificata come interi a 16 bit con o senza segno. Un file DICOM può contenere una singola immagine o più immagini. Le informazioni dell’header DICOM sono codificate tipicamente come:

TAG	| Description	| Type |	Length	| Value
--- | --- | --- | --- |--- 
0008,0022 | Acquisition Date | DA | 10 | 20120211

Il campo TAG contiene un codice composto da due valori esadecimali (gruppo, elemento del gruppo) che identificano in modo univoco un elemento dello standard DICOM. Il campo description contiene la descrizione dell’elemento (in questo caso la data di acquisizione dell’immagine). Il campo type contiene il formato dell’elemento (in questo caso una data), mentre il campo Length contiene la lunghezza dell’elemento. Il campo Value contiene il valore dell’elemento stesso in un formato definito dallo standard. In Figura 1.8 viene riportato un esempio della struttura dei metadati di un file DICOM. 

<img src="./images/image-8.png" alt="Struttura dei metadati DICOM" style="width:100%;">

*Figura 1.8. Esempio di struttura dei metadati di un file DICOM.*

In Python, l’accesso ai metadati DICOM è possibile tramite la libreria `pydicom`, che consente di leggere i file DICOM e di accedere ai singoli elementi informativi (tag) attraverso un’interfaccia ad oggetti.

### Griglia di acquisizione, risoluzione e FOV
Riepiloghiamo ora i parametri fondamentali di interesse di una immagine biomedica digitale, essendo tipicamente l’immagine memorizzata in formato DICOM nel seguito verranno forniti i nomi dei campi DICOM corrispondenti come sarà meglio dettagliato nel seguito. 
Una immagine biomedica bidimensionale può essere vista come una funzione $I(x,y)$ che trasforma una coppia di coordinate nello spazio cartesiano in un valore di intensità di segnale. Il valore I sarà legato al principio fisico di produzione dell'immagine. Una immagine biomedica digitale (quindi discreta) e le sue coordinate saranno definite in un dominio:

$$
x = (0, 1,..., N_{x}-1) \\
y = (0, 1,..., N_{y}-1) \\
I = (0, 1,..., 2^{B}-1) \\
$$

Dove $N_{x}$ e $N_{y}$ rappresentano il numero di righe e di colonne dell’immagine sui due assi (rows and columns nel formato DICOM di codifica) e $B$ rappresenta la profondità dell’immagine espressa in bit (campo Bits Allocated nel DICOM). Alcune modalità di immagine, come la TAC, permettono di definire valori negativi dell'intensità di segnale. In questo caso il range dei valori possibili sarà  $= (-2^{B}/2-1,...,2^{B}/2)$. Il formato dei dati immagazzinati è definito nel campo pixel representation del DICOM (1 signed, 0 unsigned).

#### Convenzione per gli assi
Gli assi x ed y seguono una convenzione diversa da quella usuale, dove lo zero delle coordinate è in alto a sinistra e l’asse y è orientato verso il basso come riportato in Figura 1.9. 
Il numero di pixel dell’immagine sarà dato dal prodotto del numero di righe e del numero di colonne. Il numero di pixel è legato alla risoluzione spaziale dell’immagine, in quanto a parità di campo di vista (FOV) un maggior numero di pixel corrisponde ad una minore superficie rappresentata dal pixel e quindi ad una maggiore risoluzione dell’immagine. La risoluzione dell’immagine, espressa in millimetri per pixel, è un altro importante parametro di qualità non ricavabile direttamente dall’immagine vera e propria ma dalle informazioni associate all’immagine nell’header DICOM (campo Pixel Spacing). Il pixel spacing è legato alla dimensione dell'immagine e al Field of View (cioè la dimensione della regione di spazio oggetto dell'immagine) dall'ovvia relazione 

$$
FOVx = Rows*dx \\ 
FOVy = Columns*dy \\
$$ 

dove $dx$ e $dy$ rappresentano il pixel spacing. Tipicamente sulla console di acquisizione vengono settati il $FOV$ (che ha implicazioni dirette su parametri clinici, quali la dose assorbita in TAC e gli artefatti da ribaltamento in MRI) e le dimensioni della matrice di acquisizione che ha tipicamente effetto sul tempo di acquisizione. Il pixel spacing viene definito dalla macchina di conseguenza. I pixel sono di solito quadrati (dx=dy) per la simmetria del dispositivo di acquisizione lungo il piano dell'acquisizione stessa. È importante ricordare che l'acquisizione di una immagine planare richiede comunque l'acquisizione di un segnale da una porzione finita di spazio, quindi ogni pixel corrisponde comunque ad un volume spaziale con forma a parallelepipedo con base uguale al pixel stesso e altezza dipendente dalla modalità. Ad esempio, nel caso della MRI l'altezza sarà uguale al thickness della fetta (campo Slice Thickness del DICOM). E' importante notare che il concetto di risoluzione così espresso non è equivalente al concetto di risoluzione dell’immagine biomedica da un punto di vista fisico, che rappresenta la dimensione minima di un oggetto apprezzabile da un dato sistema di imaging. A livello di acquisizione si può scegliere di avere una risoluzione peggiore di quella potenziale del dispositivo per ottimizzare altri parametri, quali il tempo di acquisizione, la dose irradiata o il rapporto segnale rumore.   

<img src="./images/image-9.png" alt="assi, FOV e pixel spacing" style="width:100%;">

*Figura 1.9. Convenzione per gli assi, FOV e pixel spacing.*

Se l’immagine biomedica descrive un volume tridimensionale, essa sarà descritta da una funzione $I(x,y,z)$. Indipendentemente dalla modalità di acquisizione (slice-by-slice o vero 3D) il volume acquisito viene salvato sotto forma di una serie di immagini 2D parallele perpendicolari all’asse z (Figura 1.10). La distanza tra le fette è uguale alla risoluzione lungo l’asse z $(dz)$. E’ importante notare che mentre i pixel sono di solito quadrati, e quindi la risoluzione lungo gli assi x e y è di solito la stessa, la risoluzione lungo l’asse z è spesso diversa ed in particolare più ridotta (quindi $dz > dx,dy$). Gli elementi fondamentali del volume dei dati (voxel) saranno quindi in forma di parallelepipedo.

<img src="./images/image-10.png" alt="slice thickness e slice gap" style="width:100%;">

*Figura 1.10. Slice thickness e slice gap.*

La risoluzione spaziale lungo z è uguale alla distanza tra due slice consecutive. Tale distanza è la somma dello slice thickness più un eventuale gap tra le slices (gap=0 vuol dire che il volume di interesse viene coperto interamente da slices adiacenti, gap>0 che porzioni del volume non vengono coperte, gap<0 che c'è un overlap tra le slices). Il valore del gap dovrebbe essere contenuto nel campo Spacing Between Slices del DICOM. Tuttavia l'uso di questo campo è fortemente arbitrario (alcune interpretazioni scrivono qui direttamente la distanza inter-slice), e il suo uso è quindi sconsigliato. La scelta più opportuna è valutare la distanza inter-slice come la distanza euclidea tra gli angoli superiori sinistri delle due slices le cui coordinate sono memorizzate  nel campo Image Position Patient.
Infine, possiamo avere immagini dinamiche acquisite nel tempo per descrivere un certo fenomeno. I questo caso definiremo risoluzione temporale delle immagini la distanza in unità temporali (millisecondi o secondi) tra due immagini successive. Ricavare la risoluzione temporale dalle informazioni dell'header DICOM è non banale. Il campo image time contiene il tempo di acquisizione dell'immagine in hh.mm.ss, e quindi non è di solito adeguato per fenomeni rapidi. Il campo Trigger Time consente di memorizzare il tempo di acquisizione in millisecondi, a partire dall’inizio dell’acquisizione. Il nome del campo deriva dal fatto che l’acquisizione viene pilotata non dall’operatore ma da un segnale esterno o interno alla macchina. Ad esempio nel caso di una acquisizione sincronizzata con l’ECG cardiaco il trigger time verrà determinato dal segnale ECG acquisito sul paziente. 

La posizione della slice o del volume nel sistema di riferimento della macchina o del paziente sono descritti nell'annex A del documento PS 3.17 (Explanatory Information) dello standard DICOM (riportato anche in Figura 1.11), liberamente accessibile in rete ad esempio dal sito http://www.dclunie.com/dicom-status.  

<img src="./images/image-11.png" alt="sistema di riferimento DICOM" style="width:100%;">

*Figura 1.11. Sistema di riferimento DICOM (Tratto da DICOM Standard Annex A PS 3.17)*

Le coordinate della slice sono fornite nel sistema di riferimento solidale al paziente, dove l'asse z segue la direzione F-H (Piedi-Testa), l'asse y la direzione A-P (Anteriore-Posteriore), l'asse x la direzione R-L (Destra-Sinistra). La posizione del sistema di riferimento paziente rispetto al sistema di riferimento dello scanner (asse z direzione di ingresso del paziente nella macchina, asse y alto-basso, asse x sinistra-destra) dipende dall'orientamento del paziente nella macchina, memorizzato nel campo DICOM Patient Position. Ad esempio il valore FFS (Feet First-Supine) indica che il paziente entra con i piedi in avanti e in posizione supina, quindi gli assi z e x sono invertiti. Il campo image position patient fornisce le coordinate in mm dell'angolo superiore sinistro (l'origine) dell'immagine nel sistema di riferimento del paziente. Il campo image orientation patient fornisce l'orientazione dei due versori che partono dall'origine dell'immagine lungo i due assi del sistema di coordinate solidale all'immagine. Ad esempio il valore 1.0\0.0\0.0\0.0\1.0\0.0 indica una immagine assiale.       

*Alcuni campi DICOM di interesse*
Group Element | Title | Esempio
---|---|---
[0028-0010]	|Rows     | 256
[0028-0011]	|Columns  | 256
[0028-0100]	|Bits Allocated| 16
[0028-0103]	|Pixel Representation | 1
[0028-0030]	|Pixel Spacing       |	1.24\1.24
[0018-0050]	|Slice Thickness     |8
[0018-0088]	|Spacing Between Slices	| ? Inaffidabile
[0020-0032]	|Image Position Patient	| -203.1\-190.1\33.9
[0020-0037]	|Image Orientation Patient | 1.0\0.0\0.0\0.0\1.0\0.0
[0018-1060]	|Trigger Time | 16
[0008-0033]	|Image Time   | 142850
[0018-5100]	|Patient Position | FFS

### PACS
Oltre alle informazioni sull’immagine prima viste lo standard DICOM (Digital Imaging and COmmunications in Medicine, immagini e comunicazione digitali in medicina) definisce i criteri per la comunicazione, la visualizzazione, l'archiviazione e la stampa. In particolare il formato DICOM contiene le informazioni utili all’identificazione del paziente, che possono essere inserite manualmente sulla console di acquisizione da parte del tecnico radiologo o nei sistemi moderni ottenute automaticamente dal sistema HIS (Hospital Information System) attraverso la lettura della cosiddetta work list (la lista degli esami da effettuare nella giornata). Una volta acquisite, le immagini DICOM vengono tipicamente memorizzate in un sistema PACS (Picture archiving and communication system), un sistema hardware e software dedicato all'archiviazione, trasmissione, visualizzazione e stampa delle immagini diagnostiche digitali. Un sistema PACS è normalmente composto da una parte di archiviazione, utilizzata per gestire dati e immagini e una di visualizzazione, che presenta l'immagine diagnostica su speciali monitor ad altissima risoluzione, sui quali è possibile effettuare la diagnosi; i sistemi PACS più evoluti permettono anche l'elaborazione dell'immagine. All’interno del PACS è possibile effettuare delle ricerche attraverso i campi DICOM (ad esempio nome del paziente, data dell’esame, tipo di esame, etc). Un sistema PACS è in grado di mantenere nella propria memoria fisica (tipicamente un array di hard disk) le immagini DICOM per un certo tempo (qualche mese) dipendente dalla quantità di immagini acquisite per giorno e dalla grandezza dell’archivio. In seguito le immagini restano disponibili su supporti di backup come DVD o magnetoottici. I dischi di un sistema PACS devono essere configurati in RAID o altra architettura ridondante in modo che la rottura di un disco non comporti una perdita di dati e possa essere sostituito “a caldo” in caso di problemi senza interrompere il funzionamento del sistema. La comunicazione tra la macchina di acquisizione e il PACS avviene attraverso le procedure definite dallo standard DICOM. Ogni macchina è definita dal proprio indirizzo di rete, dalla porta utilizzata per la comunicazione e dal proprio AETITLE (Application Entity Title). Per la comunicazione la macchina chiamante (client) deve essere dichiarata coi i propri parametri sulla macchina che funge da server. I sistemi PACS sono dispositivi medici, in quanto utilizzati per effettuare diagnosi, a meno che non rientrino nella classe I (funzione di solo archivio). Se implementano altre funzioni (anche la semplice visualizzazione) sono da considerare dispositivi medici a tutti gli effetti e come tali richiedono opportuna certificazione. Un programma che effettui analisi dell’immagine medica includerà tipicamente un client DICOM per interfacciarsi con un PACS e scaricare le immagini da elaborare. I programmi di analisi più evoluti sono in grado di salvare i risultati dell’elaborazione come “secondary DICOM’, cioè file DICOM non prodotti da un dispositivo di acquisizione ma frutto di elaborazioni successive.

La figura 1.12 mostra la tipica architettura di rete in un centro radiologico. I dispositivi di acquisizione (scanner), ad esempio TAC, MR, PET, etc convogliano le immagini acquisite nel PACS. Dal PACS è possibile stampare lastre radiografiche, produrre CD/DVD per i pazienti, effettuare il backup dei dati, etc.  Un programma di elaborazione di immagini scaricherà i dati dal PACS ed eventualmente salverà i risultati sul PACS stesso alla fine del processo.

<img src="./images/image-12.png" alt="Architettura di un sistema PACS" style="width:100%;">

*Figura 1.12. Architettura di un sistema PACS*

## Analisi dell'immagine biomedica
Il problema dell’analisi dell’immagine biomedica è parte della cosiddetta computer vision (visione artificiale), una branca dell’intelligenza artificiale che ha origine negli anni 60 del secolo scorso e che si occupa di implementare algoritmi che riproducano le funzioni della visione umana. Un sistema di computer vision è tipicamente strutturato in una serie di operazioni classificate in ordine di complessità come:
1. **Image Acquisition.** Include l’acquisizione delle immagini da elaborare attraverso fotocamere, videocamere ,etc. Nell’imaging biomedico corrisponde alla fase di acquisizione delle bioimmagini attraverso i vari dispositivi di acquisizione.
2. **Image pre-processing.** Include le operazioni a basso livello sull’immagine, come la riduzione del rumore, il miglioramento del contrasto, il cambio della scala di rappresentazione. Nell’imaging biomedico questa fase include gli algoritmi di interpolazione, compressione e filtraggio.
3. **Feature extraction.** Include l’estrazione dalle immagini di caratteristiche geometriche di interesse, come linee, punti, curve ed i cosiddetti blob, cioè aggregati di pixel con caratteristiche comuni. 
4. **Detection/Segmentation.** Include l’estrazione dall’immagine di oggetti di interesse, ad esempio separando lo sfondo dell’immagine e estraendo dalla scena gli oggetti visibili. Nell’imaging biomedico i punti 3 e 4 della computer vision vengono tipicamente raggruppati negli algoritmi di segmentazione o pattern recognition. Si noti che in questa fase gli oggetti vengono estratti ma non riconosciuti.    
5. **High-level processing.** Questa fase include le operazioni ad alto livello legate al riconoscimento degli oggetti, cioè alla loro classificazione. Nell’imaging biomedico abbiamo la corrispondenza con gli algoritmi di classificazione e registrazione delle bioimmagini. 
6. **Decision Making.** In questa fase le informazioni ottenute nelle fasi precedenti vengono utilizzate per determinare una azione da intraprendere. Nell’imaging biomedico questo corrisponde ad effettuare una diagnosi con metodi di intelligenza artificiale. 

In questo corso analizzeremo i punti 2-5. 

### Modello dell'immagine biomedica
Nell'ingegneria è diffusa la credenza che sia possibile sviluppare modelli matematici che approssimino il mondo reale con sufficiente accuratezza e il campo dell'imaging biomedico non fa eccezione. Definiamo quindi l’immagine biomedica ideale come un insieme di regioni non sovrapposte ognuna caratterizzata da un certo livello di grigio. Ogni livello di grigio e quindi ogni regione corrisponderà ad un tessuto. Avremo quindi:
$$
\begin{aligned}
I_0(x,y) &= \sum_{i=1}^{k} P_i(x,y) ; \quad P_i(x,y) &=
\begin{cases}
s_i & \text{se } V(x,y) \in d_i \\
0   & \text{altrove}
\end{cases}
\end{aligned}
$$
ed i domini $d_{i}$ sono disgiunti. $k$ è “piccolo”, nel senso che il numero di tessuti costituenti è limitato. In generale tanto più grande è $k$ tanto più il modello sarà simile all'immagine reale, fino a $k$ uguale al numero di pixel dell'immagine quando si ha l'identità completa tra modello e immagine ed il modello diviene totalmente inutile. Per comprendere il senso del modello, si pensi a quale è il fine diagnostico dell'imaging medico. Quello che si vorrebbe è che a ogni tessuto venga associato in modo univoco un singolo valore di segnale, in modo che ogni tessuto sia distinguibile dagli altri senza possibilità di errore. Una immagine di questo tipo che presenta la corrispondenza univoca tessuto → valore di segnale è l'immagine biomedica ideale ai fini diagnostici e coincide con $I_{0}$. In un certo senso l'elaborazione dell'immagine biomedica si potrebbe definire come l'insieme delle tecniche che consentono di estrarre l'immagine ideale $I_{0}$ dall'immagine reale come acquisita dal dispositivo di imaging. Un esempio di immagine ideale e immagine reale è riportato in Figura 1.13. 

<img src="./images/image-13.png" alt="imm ideale, imm reale" style="width:100%;">

*Figura 1.13. Sinistra: Immagine reale. Destra: immagine ideale.*

Introduciamo ora nel modello i fattori che corrompono l'immagine ideale:

1. **Rumore biologico.** 
Alcuni tessuti non sono omogenei ma caratterizzati da un struttura interna. Ad esempio nel cuore il sangue che riempie i due ventricoli potrà in generale essere considerato omogeneo essendo un liquido (non considerando il movimento del sangue stesso) mentre il muscolo cardiaco sarà caratterizzato da una struttura a fibre che produce una disomogeneità nell’immagine. Questo fenomeno viene definito “rumore biologico” $n_{B}(x,y)$, nel senso che le proprietà intrinseche del tessuto divergono dal modello ideale. Evidentemente il concetto di rumore biologico è legato alla risoluzione dell’immagine, che determina la grandezza delle disomogeneità rilevabili. Nell’esempio precedente, il sangue è disomogeneo a livello microscopico (globuli rossi e bianchi, piastrine, etc) ma omogeneo a livello della risoluzione MRI (> 1mm).  
2. **Effetto volume parziale (partial volume effect, PVE).** Il fatto che il processo di acquisizione sia discreto implica che il segnale viene acquisito in un certo volume di spazio pari alla risoluzione spaziale della metodica. Se due tessuti convivono nello stesso volume elementare, il voxel corrispondente dell’immagine assumerà un valore di livello di grigio intermedio tra i valori caratteristici dei due tessuti (effetto volume parziale, Figura 1.14). Questo effetto viene modellato attraverso la convoluzione con un kernel gaussiano $h(x,y)$, che corrisponde ad una operazione di smoothing dei contorni dell'immagine. Infatti l'effetto volume parziale agisce solo sulle zone di transizione tra i due tessuti.

<img src="./images/image-14.png" alt="PVE" style="width:50%;display:block; margin:0 auto;">

*Figura 1.14. Esempio di effetto di volume parziale (PVE).*

3. **Attenuazione.** In molti casi l’immagine biomedica sarà affetta da un processo di attenuazione del segnale, che produce una distorsione continua dell’immagine lentamente variabile. Nella MRI ad esempio avremo un effetto indotto dalla disomogeneità nel campo magnetico statico o dalla sensibilità delle bobine, mentre negli ultrasuoni l’effetto sarà legato alla distanza del tessuto dalla sonda. L’effetto di attenuazione verrà descritto da un campo moltiplicativo $g(x,y)$. Il campo moltiplicativo è tipicamente caratterizzato dall'essere “smooth”, cioè dal fatto che varia lentamente senza brusche transizioni. 
4. **Rumore.** Infine l’immagine sarà corrotta da rumore con una certa distribuzione $n(x,y)$, che dipende dal processo fisico utilizzato per l'acquisizione. Ad esempio in MRI il rumore avrà distribuzione di tipo Riciano, negli US avrà distribuzione di Rayleigh, etc. Al contrario di quanto avviene per il rumore Gaussiano, il rumore non è necessariamente di tipo additivo. Un esempio di rumore non additivo verrà introdotto nel seguito.

In definitiva l’immagine osservata $I(x,y)$ sarà descritta dalla relazione:
$$
I(x,y)=[[I_{0}(x,y)+n_{B}(x,y)]*h(x,y)]g(x,y)+n(x,y)
$$

il simbolo + che precede il rumore non va inteso in senso rigorosamente additivo come prima detto. 
La stima dell’immagine ideale $I_{0}(x,y)$ comporta la stima di tutti gli elementi compresi nella formula, nota $I(x,y)$ che è l’immagine reale. Il problema è naturalmente molto complesso e non prevede una soluzione unica. In generale l’approccio utilizzato è quello di modellare le varie componenti in base a dati noti e trovare una soluzione minimizzando un qualche funzionale. 

### Istogramma
È di interesse interpretare quanto detto finora dal punto di vista dell'Istogramma dell'immagine. Un istogramma è una rappresentazione statistica della distribuzione dei livelli di grigio nell’immagine. 
In ascissa abbiamo i possibili valori di livello di grigio ed in ordinata il numero di pixel che assumono quel determinato valore. Se normalizziamo i valori dell’istogramma per il numero totale di pixel, l’istogramma normalizzato rappresenterà la probabilità di trovare nell’immagine un pixel con quel valore. Spesso l’asse x viene quantizzato in un certo numero di regioni (bins) e lungo l’asse y viene riportato il numero di pixel con valore compreso nel bin per migliorare la qualità visiva dell'istogramma. 
L'istogramma dell'immagine ideale $I_{0}$ sarà costituito da $k$ picchi di altezza pari al numero di pixel appartenenti al dominio $k$. Si consideri ad esempio l'immagine in Figura 1.15 a 6 pattern e il relativo istogramma, definito da 6 picchi distinti con altezza uguale al numero di pixel appartenenti al pattern.   

<img src="./images/image-15.png" alt="istogramma immagine ideale" style="width:100%;">

*Figura 1.15. Esempio di istogramma per un'immagine ideale.*

#### Effetto volume parziale (PVE)
Se effettuiamo una operazione di smoothing (filtro a media mobile) simulando l’effetto volume parziale, l'istogramma si trasforma come in Figura 1.16. Come si osserva i bordi dell’immagine si sfumano e nell'istogramma compaiono dei nuovi valori dei livelli di grigio tra i picchi, distribuiti in modo uniforme. Infatti la percentuale di tessuti diversi che ricade all'interno della finestra di smoothing è distribuita casualmente secondo una distribuzione uniforme. 

<img src="./images/image-16.png" alt="istogramma immagine pve" style="width:100%;">

*Figura 1.16. Esempio di istogramma per un'immagine con PVE.*

Questo è ciò che accade anche nella procedura di acquisizione reale a causa del PVE. Se in un voxel si trovano due tessuti con segnale $S_{1}$ e $S_{2}$, il segnale risultante del voxel sarà:
$$
S = pS_{1}+(1-p)S_{2}
$$
dove $p$ compreso tra 0 e 1 è la percentuale di voxel occupato dal tessuto 1. Evidentemente il valore di $S$ sarà compreso tra $S_{1}$ per $(p=1)$ e $S_{2}$ per $(p=0)$. Nelle immagini biomediche reali p si può considerare distribuito in modo uniforme, in quanto l’oggetto dell’imaging ha forma irregolare e la griglia di acquisizione e la forma dell’oggetto di cui si fa l’imaging non hanno nessuna relazione particolare. Si assumerà quindi una distribuzione di probabilità uniforme tra i valori $S_{1}$ e $S_{2}$. Si noti che in casi molto particolari, come quello di un fantoccio cubico con le facce parallele agli assi x e y del riferimento di acquisizione questa assunzione può non essere vera. 
Quanto detto si può estendere alla compenetrazione di tre o più tessuti nello stesso voxel.
  
Possiamo quindi concludere che in generale:

1. Il PVE introduce nuovi livelli di grigio, compresi tra il livello minimo e il livello massimo dei due tessuti interessati nell'immagine ideale.
2. I livelli di grigio creati sono distribuiti uniformemente tra i picchi dei tessuti adiacenti.
3. Il numero di livelli creati dipende dal perimetro dei pattern e non dalla loro area.    

In una immagine reale, a parità di oggetto di cui si fa l’imaging, l’incidenza del PVE dipende dalla risoluzione. Usando pixel più piccoli la percentuale di pixel affetti dal PVE sarà minore. Come detto in precedenza, anche in caso di immagine planare il segnale di un pixel sarà sempre originato da un volume spaziale finito di forma parallelepipodale. Esisterà quindi anche un PVE in direzione perpendicolare al piano di acquisizione, tanto più marcato quanto maggiore è il thickness della fetta.   

#### Effetto dell'attenuazione
L'attenuazione dell'immagine è modellata da un processo moltiplicativo per cui lo stesso tessuto in parti diverse dell'immagine assume valori diversi. Dal punto di vista dell’istogramma avremo un allargamento e una deformazione dei picchi.  In Figura 1.17 osserviamo una immagine ideale composta di tre tessuti ed il relativo istogramma. L’immagine viene moltiplicata per un campo di attenuazione il cui andamento è mostrato in Figura 1.18, originando una nuova immagine con livelli di grigio distorti. L’istogramma dell’immagine attenuata risulta distorto.     

<img src="./images/image-17.png" alt="campo di attenuazione" style="width:50%;display:block; margin:0 auto;">

*Figura 1.17. Esempio di campo di attenuazione.* 

<img src="./images/image-18.png" alt="istogramma immagine con attenuazione" style="width:100%;">

*Figura 1.18. Istogramma immagine con effetto di attenuazione.*

#### Effetto del rumore
Il rumore, se gaussiano a media nulla, crea un allargamento dei picchi dell'istogramma. Infatti si creano dei livelli di grigio che deviano dal valore teorico dei pattern tanto più quanto più è grande la deviazione standard del processo di rumore. Un esempio di effetto di rumore Gaussiano additivo è riportato in Figura 1.19.

<img src="./images/image-19.png" alt="istogramma immagine con rumore" style="width:100%;">

*Figura 1.19. Istogramma immagine con rumore Gaussiano additivo.*

Applicando tutti i fattori di disturbo otteniamo l’immagine reale (Figura 1.20).
Come si osserva l’istogramma dell’immagine è modificato in modo dipendente dal peso e dalle caratteristiche dei vari fattori di disturbo.

<img src="./images/image-20.png" alt="istogramma immagine con pve, attenuazione e rumore" style="width:100%;">

*Figura 1.20. Istogramma immagine con pve, attenuazione e rumore.*

Se calcoliamo la differenza tra l’immagine reale e l’immagine ideale otteniamo l'immagine e l'istogramma di Figura 1.21.

<img src="./images/image-21.png" alt="immagine differenza" style="width:100%;">

*Figura 1.21. Istogramma dell'immagine differenza.*

Si nota come la differenza tra le due immagini sia più pronunciata nelle zone di transizione tra tessuti (che sono quelle di interesse clinico), mentre è minore nelle zone omogenee. L’istogramma della differenza mostra come la maggior parte degli errori siano piccoli (si addensano intorno allo zero), ma esistono anche variazioni molto grandi.

### Entropia
I vari processi di distorsione dell'immagine possono essere quantificati introducendo il concetto di Entropia dell’immagine.
L’entropia di Shannon di una immagine $I$ è una quantità definita dalla teoria dell’informazione ed è data da:
$$
H(I) = - \sum_{g_i \in G} \log\!\bigl(P(I = g_i)\bigr)\, P(I = g_i)
$$

Dove $g_{i}$ sono i livelli di grigio dell’immagine $I$ appartenenti all’insieme $G$ dei possibili livelli di grigio, determinato dalla profondità dell’immagine. $P(I=g_{i})$ è la probabilità che un pixel dell’immagine assuma il valore $g_{i}$. Essendo $P(I=g_{i})$ sempre minore o uguale ad uno, l’entropia $H$ assume sempre valori positivi ed assume il valore nullo solo nel caso di $P(I=g_{i}) = 1$ per un singolo valore di $i$, quindi nel caso di una immagine uniforme composta da un solo pattern. Secondo la teoria di Shannon, l’entropia esprime la quantità di informazione contenuta nell’immagine. Una immagine composta da rumore avrà massima entropia mentre una immagine composta da un singolo valore avrà entropia minima. In questo senso, stabilita la configurazione dei pattern che costituiscono l’immagine, l’immagine ideale avrà entropia minore rispetto alle immagini ottenute applicando i vari fattori di disturbo. 
La probabilità $P(I=g_{i})$ utilizzata per il calcolo dell’entropia non è altro che l’istogramma normalizzato per il numero di pixel dell’immagine, quindi possiamo scrivere:

$$
H(I) = -\frac{1}{N} \sum_{i=1}^{N} h_I(i)\, \log\!\left(\frac{h_I(i)}{N}\right)
$$

dove $h_{I}$ è l’istogramma di $I$ e $N$ è il numero di pixel di $I$.

Per cui l‘entropia può essere calcolata facilmente dall’istogramma dell’immagine.  
In Figura 1.22 sono riportati l’istogramma ed il valore di entropia per i casi di immagine random (composta da rumore casuale, entropia massima), immagine ad un singolo pattern (entropia nulla), immagine a due pattern, immagine a due pattern corrotta da rumore gaussiano, immagine a due pattern corrotta da effetto volume parziale. Come si osserva dagli ultimi tre esempi, l’entropia cresce in dipendenza dai fattori che allontanano l’immagine reale dall’immagine ideale.  

<img src="./images/image-22.png" alt="Valori di entropia per diversi tipi di istogramma" style="width:100%;">

*Figura 1.22. Valori di entropia per diversi tipi di istogramma.* 

## Qualità dell'immagine biomedica
Il fine di una immagine biomedica è quello di permettere un diagnosi il più possibile accurata da parte del medico. La nozione di qualità dell’immagine biomedica non è facilmente definibile, visto che il modo in cui l’immagine viene utilizzata dall’operatore per definire la diagnosi è fortemente soggettivo e non descrivibile in modo rigoroso. D’altra parte la necessità di definire la qualità di immagine è un punto importante nella progettazione e “quality assessment” dei dispositivi biomedici. 
Un modo comune per rendere maggiormente oggettiva la misura di qualità è l’uso di “phantom”, cioè di fantocci che possono essere costruiti in modo riproducibile e quindi utilizzati per misure ripetute escludendo dalla misura la variabilità dovuta al paziente. Tipicamente le macchine per l’acquisizione di immagini biomediche hanno in dotazione uno o più phantom standardizzati che consentono il quality assessment periodico delle prestazioni del dispositivo. Nel seguito verranno descritti alcuni indici utilizzati comunemente nella misura di qualità dell’immagine biomedica. 

### Qualitativa o semi-quantitativa 
La valutazione viene effettuata da un operatore esperto, che può utilizzare una scala predefinita con un certo numero di livelli per standardizzare la valutazione (analisi semi-quantitativa). La valutazione risulta chiaramente fortemente dipendente dall’operatore. Per minimizzare questo fattore la valutazione può essere fatta da più operatori, mediando i risultati ed eventualmente eliminando i valori estremi. 
Una scala usata correntemente è quella a cinque punti, ad esempio:

1. nondiagnostic study
2. poor or suboptimal study
3. acceptable
4. good
5. excellent

La qualità dell’immagine sarà quindi espressa da un numero compreso tra 1 e 5 (anche frazionario se sono coinvolti più osservatori) proporzionale alla qualità dell’immagine.
 
In questo caso il processo di valutazione comporterà l'analisi di un certo numero di immagini da parte di operatori esperti con l'attribuzione di un punteggio di qualità. La media dei punteggi (o la mediana volendo escludere i punteggi “estremi”) rappresenterà l'indice di qualità assegnato all'immagine.   

### SNR e CNR
L'SNR e il CNR rappresentano due parametri di qualità largamente utilizzati nella valutazione delle immagini. Facciamo riferimento ad un modello semplificato di immagine biomedica dove l’immagine reale è data dalla somma dell’immagine reale e del rumore. 

$$
I(x,y)=I_{0}(x,y)+n(x,y)
$$

La natura del rumore $n$ dipenderà dal processo fisico di acquisizione, per ora supponiamo che il rumore sia gaussiano con media nulla e deviazione standard $ \sigma$.  
In figura osserviamo a sinistra una immagine ideale composta da tre regioni con valore di segnale $s1=50$, $s2=150$, $s3=200$ e a destra la stessa immagine corrotta da rumore con $\sigma=10$. L’immagine sintetica di Figura 1.23 imita un phantom usato per la misura di qualità in MRI, costituito da due cilindri concentrici in plastica riempiti con due liquidi diversi. Si tratta quindi di un phantom con due tessuti perfettamente omogenei. 

<img src="./images/image-23.png" alt="Fantoccio: caso ideale e reale e relativi istogrammi" style="width:100%;">

*Figura 1.23. Fantoccio: caso ideale e reale e relativi istogrammi.*

Si nota come il rumore allarghi la distribuzione del segnale relativa ai vari tessuti, fino a far confondere tra loro pixel appartenenti a tessuti diversi. Maggiore è la deviazione standard del rumore rispetto al valore del segnale, tanto peggiore è la qualità dell’immagine. Si definisce quindi l’$SNR$ (rapporto segnale rumore) come:

$$
SNR = \frac{M_{i}}{\sigma_{i}}
$$

Il rapporto segnale rumore ($SNR$) è quindi il rapporto tra il valor medio del segnale in una regione e la deviazione standard ($\sigma$, SD) del rumore nella stessa regione. L’$SNR$ dà quindi una misura di quanto il valore del segnale ottenuto dal dispositivo di imaging è corrotto dal rumore. A livello di acquisizione, σ è tipicamente una costante dipendendo dal rumore introdotto dal processo di acquisizione (detettori, amplificatori, etc). Quindi l’$SNR$ dipenderà dalla risoluzione dell’immagine (nel senso che più piccolo è il voxel meno segnale verrà acquisito e quindi $M$ sarà più piccolo diminuendo l’$SNR$) e dal tempo di acquisizione (maggior tempo di acquisizione incrementa $M$ aumentando l’$SNR$). L’$SNR$ ottimo è quindi un compromesso tra qualità dell’immagine, tempo di acquisizione e risoluzione. 

Nell’uso clinico è in realtà più importante il contrasto, cioè la capacità del dispositivo di imaging di distinguere due tessuti diversi. Si introduce quindi il $CNR$:

$$
CNR = \frac{2|M_{i}-M_{j}|}{\sigma_{i}+\sigma_{j}}
$$

Il $CNR$ (rapporto contrasto-rumore) è il rapporto tra la differenza dei valori medi del segnale nelle due regioni e il rumore medio nelle due regioni. Sul $CNR$ valgono le stesse considerazioni fatte per l’$SNR$.

Questi indici possono essere valutati in modo manuale tracciando sull’immagine delle regioni di interesse (ROI) e calcolando il valor medio e la deviazione standard del segnale nelle ROI stesse.
E’ evidente che la misura va effettuata in regioni omogenee dell’immagine e che maggiore è l’area della ROI utilizzata maggiore sarà la precisione della misura. Un limite alle dimensioni della ROI è dato dal PVE, nel senso che i bordi della ROI devono essere lontani dai bordi dei tessuti per evitare di includere regioni dove è presente il PVE. ROI troppo grandi possono dare un valore errato di SNR/CNR se sono presenti fenomeni di attenuazione. Un esempio di tracciamento di ROI per il calcolo del $CNR$ è riportato in Figura 1.24. 

<img src="./images/image-24.png" alt="Esempio CNR" style="width:50%;display:block; margin:0 auto;">

*Figura 1.24. Esempio di tracciamento ROI per calcolo CNR.*

Per ottimizzare la misura si possono far coincidere le ROI con l’intera immagine, acquisendo due immagini dello stesso oggetto con gli stessi parametri di acquisizione. L’immagine ideale non cambia perché l’oggetto è lo stesso, quindi sottraendo le due immagini avremo una immagine differenza dipendente solo dal processo di rumore:

$$
\begin{aligned}
I_1(x,y) &= I_0(x,y) + n_1(x,y) \\
I_2(x,y) &= I_0(x,y) + n_2(x,y) \\
\Delta I &= I_2(x,y) - I_1(x,y) = n_2(x,y) - n_1(x,y) = n_d(x,y)\\ 
\end{aligned}
$$

Anche se il rumore è gaussiano, la differenza delle due distribuzioni di rumore $n_{d}(x,y)$ non sarà in generale gaussiana. Una stima superiore della SD dell’immagine differenza è   volte la SD delle due componenti. Misurando quindi la SD sull’immagine differenza e dividendo per  avremo una misura oggettiva del limite superiore del rumore dell’immagine. Notiamo che in questo caso la misura di SD può essere fatta su tutta l’immagine, migliorando la qualità della misura. Un altro vantaggio è che la misura può essere facilmente automatizzata. Questa tecnica può essere utilizzata in sede di valutazione delle apparecchiature quando è possibile acquisire immagini di oggetti inanimati, detti nel gergo phantom o fantocci. Non ha ovviamente significato su immagini acquisite da pazienti dove è impossibile avere due immagini esattamente identiche a causa del movimento del soggetto. 

Un altro metodo automatico utilizzabile è quello di estrarre dall’immagine una serie di regioni, ad esempio quadrati di 16x16 pixel. Estratte le regioni, si calcola la SD e si ordinano le regioni per SD crescente. Eliminate le regioni con SD più alto, che sono quelle dove sono presenti più tessuti, il valore di SD rimasto è rappresentativo del rumore.

Quando si effettua una misura su fantoccio è garantita l’omogeneità del tessuto su cui viene effettuata la misura. Quando invece si esaminano immagini di un paziente reale, un problema ulteriore è dato dal fatto che i tessuti di cui si fa l’imaging non sono omogenei come nel modello ideale, ma presentano una struttura (fibre muscolari, etc.). Quindi esiste una variabilità non dovuta al rumore di acquisizione ma alla struttura stessa dell’oggetto (il cosiddetto rumore biologico). Per ovviare a questo inconveniente il rumore può essere stimato sullo sfondo dell’immagine, dove non è presente nessun tessuto. Infatti se vale l’assunzione:

$$
I(x,y)=I_{0}(x,y)+n(x,y)
$$

La SD del rumore è la stessa su tutti i tessuti e quindi anche sul fondo, dove tra l’altro è possibile tracciare una ROI di dimensioni tali da garantire una buona stima dell’SD. In molti casi quando la misura dell’SNR e del CNR viene effettuata su immagini reali si utilizzano quindi le formule:

$$
SNR = \frac{M_{i}}{\sigma_{BK}}
$$

e

$$
CNR = \frac{|M_{i}-M_{j}|}{\sigma_{BK}}
$$

Dove il valor medio è misurato su una ROI nel tessuto di interesse e la SD su una ROI tracciata nel fondo dell’immagine.  Questa tecnica è molto apprezzata dai produttori di dispositivi di acquisizione in quanto consente di ottenere valori di SNR e CNR superiori a quelli reali “visti” dall’operatore come si vedrà nel seguito. 

#### Nota sulla natura del rumore in MRI
È importante notare come misurare la SD nel fondo dell’immagine abbia senso se e solo se il rumore è di tipo additivo. Questo non è il caso di molte modalità di imaging. Ad esempio, nella MRI le immagini sono ricostruite dal K-spazio, che rappresenta il dominio della frequenza. La parte reale ed immaginaria del K-spazio rappresentano i due canali (fase e quadratura) attraverso i quali viene demodulato il segnale. Il rumore di acquisizione si inserisce al livello dei due canali e viene modellato come gaussiano bianco con SD uguale sui due canali. Per riportare le immagini nel dominio dello spazio, si calcola la trasformata di Fourier inversa del K-spazio ottenendo una immagine complessa $c(k,l)$:

$$
c(k,l) = p(k,l) + n_p(k,l) + j \bigl[ q(k,l) + n_q(k,l) \bigr]
$$

dove $p$ e $q$ sono la parte reale e immaginaria dell’immagine ideale e np e nq rappresentano il rumore introdotto sui due canali. 
Il modulo di $c(k,l)$, che rappresenta l’immagine MRI comunemente usata, è dato da:

$$
z(k,l) = \lvert c(k,l) \rvert
       = \sqrt{\bigl(p(k,l) + n_p(k,l)\bigr)^2
               + \bigl(q(k,l) + n_q(k,l)\bigr)^2}
$$

La non linearità introdotta dall’operazione di modulo cambia la distribuzione del rumore che diviene di tipo Riciano. Il rumore Riciano non è più additivo, ma moltiplicativo, e quindi il rumore sarà diverso in regioni diverse dell’immagine.
Se il valore dell’immagine è molto più alto del rumore, si può scrivere trascurando i termini di rumore al quadrato:

$$
\begin{aligned}
z(k,l) &= m(k,l) + \frac{p(k,l)\, n_p(k,l) + q(k,l)\, n_q(k,l)}{m(k,l)} \\
       &= m(k,l) + n_z(k,l)
\end{aligned}
$$

con

$$
\begin{aligned}
m(k,l) &= \sqrt{p(k,l)^2 + q(k,l)^2}, \\
n_z(k,l) &= \frac{p(k,l)\, n_p(k,l) + q(k,l)\, n_q(k,l)}{m(k,l)} .
\end{aligned}
$$

Riconducendoci al caso di m immagine di modulo ideale e nz rumore additivo.
La SD del rumore sarà:

$$
\sigma_z
= \sqrt{\frac{p(k,l)^2\,\sigma_n^2 + q(k,l)^2\,\sigma_n^2}{m(k,l)^2}}
= \sigma_n
$$

Quindi in regioni di elevata intensità di segnale il rumore si può considerare gaussiano con SD uguale alla SD sui due canali. 
Nelle regioni a bassa intensità, come lo sfondo dell’immagine, la distribuzione Riciana è simile alla distribuzione di Rayleigh. Per lo sfondo (segnale nullo) abbiamo:

$$
z_B(k,l) = \sqrt{n_p(k,l)^2 + n_q(k,l)^2}
$$

$$
\sigma_B^2 = \left( 2 - \frac{\pi}{2} \right) \sigma_n^2,
\qquad
\sigma_n = 1.526\, \sigma_B .
$$

Quindi nelle immagini MRI, se misuriamo il rumore sullo sfondo otterremo una sottostima del rumore di un fattore 1.526. Questo in realtà è vero per una bobina a singolo canale, per bobine multicanale il fattore di conversione cambia leggerment [1]. Nel caso di immagini MR, la formula corretta da utilizzare sarà quindi:

$$
SNR = \frac{M_{i}}{1.526\sigma_{BK}}
$$

e

$$
CNR = \frac{|M_{i}-M_{j}|}{1.526\sigma_{BK}}
$$

Dove il valor medio è sempre misurato su una ROI nel tessuto di interesse e la SD su una ROI tracciata nel fondo dell’immagine. Questa tecnica è un po’ meno apprezzata dai produttori di dispositivi di acquisizione in quanto ottiene valori di SNR e CNR inferiori rispetto all’assunzione di rumore additivo. In conclusione, nella valutazione del rumore associato ad una immagine biomedica è importante tener conto della fisica dell’acquisizione per effettuare una valutazione corretta. Nel confrontare misure su dispositivi diversi, è importante conoscere che procedura è stata utilizzata per la misura di SNR e CNR.  

### Just Noticeable Difference (JND)
L’indice $JND$ indica il valore di incremento relativo del segnale rispetto allo sfondo dopo il quale un oggetto diventa visibile. Si ha quindi $JND = (F-B)/B$ dove $B$ è il segnale dello sfondo e $F$ è il segnale dell’oggetto. E’ stato dimostrato (Weber law) che il valore di $JND$ è largamente indipendente dal valore di $B$ è vale intorno al 2%. Questa assunzione vale nel caso di assenza di rumore, nei casi reali $F$ e $B$ saranno ovviamente delle stime ottenute come media del segnale su una ROI e il valore di $JND$ utile per distinguere i due tessuti sarà più alto.    

In Figura 1.25 è riportato un tipico esperimento per la valutazione del JND, la prima barra ha un JND del 3% (tratto da R Rangayyan, Biomedical Image Analysis, CRC Press 2004). Alcuni fantocci TAC implementano il test JND includendo una serie di inserti con valori JND crescenti. Il test di qualità fatto con tali fantocci prevede il riconoscimento del numero massimo possibile di inserti da parte dell’operatore. I risultati del test JND hanno evidentemente un certo grado di soggettività dipendendo dall’acume visivo dell’operatore, dal monitor usato, dall’illuminazione ambientale, etc.     

<img src="./images/image-25.png" alt="JND" style="width:100%;display:block; margin:0 auto;">

*Figura 1.25. JND.*

### Analisi dei profili 
Come introdotto nel modello dell’immagine biomedica, un fattore importante nella valutazione della qualità di immagine è la minimizzazione dell’effetto di smoothing dei bordi dovuto all’effetto volume parziale (partial volume effect, PVE). Per valutare il PVE è possibile estrarre dall’immagine un profilo, che è il grafico dell’intensità di segnale rispetto ad una certa direzione. Per quanto sia possibile estrarre profili anche lungo direzioni oblique, solitamente per evitare problemi dovuti all’interpolazione si preferisce estrarre i profili lungo le coordinate principali (x,y, o z).       
Consideriamo la Figura 1.26 dove viene riportata un'immagine costituita da uno sfondo di valore 50 con all’interno un quadrato di valore 255. Se tracciamo un profilo lungo x avremo un grafico che presenta due transizioni istantanee. Se applichiamo una operazione di smoothing (che simula il PVE), il profilo apparirà smussato rispetto al caso ideale. Per un PVE ancora maggiore l’effetto di smoothing del profilo si incrementa ulteriormente. E’ quindi ragionevole utilizzare la velocità di transizione del segnale tra due regioni diverse valutata su uno o più profili come indice di qualità dell’immagine. Più rapida la transizione, minore il PVE e migliore la qualità di immagine.  

<img src="./images/image-26.png" alt="Profili per diversi valori di PVE" style="width:100%;display:block; margin:0 auto;">

*Figura 1.26. Profili per diversi valori di PVE.*

Intuitivamente, un parametro di qualità dovrebbe essere correlato all’intervallo spaziale $(b-a)$ in cui avviene la transizione e all’altezza del gradino $f(b)-f(a)$ (Figura 1.27). Un possibile parametro è quindi il valore del gradiente dell’immagine nella direzione x definito come:

$$
G_{x}=\frac{f(b)-f(a)}{b-a}
$$

Un gradiente maggiore corrisponde a contorni meglio definiti e quindi ad una immagine di migliore qualità.

<img src="./images/image-27.png" alt="Stima del profilo" style="width:100%;display:block; margin:0 auto;">

*Figura 1.27. Stima del profilo (tratto da R Rangayyan, Biomedical Image Analysis, CRC Press 2004)*

È stato verificato da Higgins e Jones che il gradiente non è ben correlato con la percezione visiva di un osservatore umano, e quindi può non essere adatto ad una valutazione di qualità delle immagini biomediche. E’ stato quindi proposto un parametro detto acutezza (acutance) definito come:

$$
A = \frac{1}{f(b) - f(a)} \int_{a}^{b}
\left[ \frac{d}{dx} f(x) \right]^2 \, dx
$$

che meglio correla con la percezione visiva della definizione dei contorni. In ogni caso le misure devono essere ripetute in varie direzioni e in varie interfacce tra tessuti per essere significative.
Mentre per una immagine ideale priva di rumore è facile definire $a$ e $b$ come i punti a sinistra e a destra della transizione (ad esempio se i due tessuti hanno valore 50 e 200 b sarà il punto in cui f assume il valore 200 ed a il punto in cui f assume il valore 50), nelle immagini reali affette da rumore sarà necessario definire una soglia per stabilire l’inizio e la fine della transizione. 


Fortemente connesso al concetto di acutezza è il concetto di Point Spread Function (PSF) riportata in Figura 1.28. La PSF rappresenta l’immagine reale di un punto singolo, ed è quindi in qualche modo la funzione di trasferimento del processo di formazione reale dell’immagine.    
 
<img src="./images/image-28.png" alt="Point spread function" style="width:100%;display:block; margin:0 auto;">

*Figura. 1. 28. Point spread function (Tratto da R Rangayyan, Biomedical Image Analysis, CRC Press 2004). *

Da un punto di vista matematico se definiamo un punto ideale nell’immagine ideale come un delta di Dirac, l’immagine reale in uscita dal sistema di imaging sarà la PSF del sistema. 
Se il sistema è lineare e invariante rispetto alla spazio (sistema LSI), l’immagine reale in uscita dal sistema sarà $g = PSF * f$ dove $f$ è l’immagine reale e $*$ rappresenta la convoluzione spaziale.  
Come tipicamente rappresentato nella figura, la PSF è di solito una funzione gaussiana 2D, il che giustifica l’uso della convoluzione con una gaussiana nel modello dell’immagine biomedica per modellare il PVE. In via di principio è possibile fare l’imaging di un oggetto puntiforme (in realtà per evidenti motivi fisici un oggetto di dimensioni molto piccole) e tracciare i profili della PSF risultante che saranno delle funzioni gaussiane. La larghezza di tali profili (espressa ad esempio come SD della gaussiana) sarà un misura della bontà del sistema di imaging. E’ evidente che questo metodo richiede l’uso di un fantoccio standardizzato o di una procedura di imaging standardizzata per ottenere la PSF. 

Infine un profilo tracciato sull’immagine di un fantoccio omogeneo che riempia tutto o buona parte del campo visivo (FOV) del dispositivo può permettere di valutare il campo di attenuazione g introdotto nel modello di immagine biomedica. Nel caso di g unitario (quindi assenza di attenuazione) il profilo dovrebbe risultare perfettamente orizzontale, mentre per $g < 1$ compare una curvatura del profilo, tanto maggiore quanto maggiore è l’attenuazione.    

### Artefatti
Le immagini biomediche possono essere corrotte da artefatti. Gli artefatti sono strutture riconoscibili, quindi con una coerenza interna, che appaiono sull’immagine anche se non esistono nell’oggetto reale. Il rumore è invece un disturbo completamente casuale, privo di struttura e distribuito uniformemente sull’immagine. La figura mostra due esempi di artefatti in immagini MRI. Gli artefatti sono tipicamente non predicibili e vengono valutati attraverso la probabilità della loro comparsa su lunghe serie di acquisizioni. Alcuni tipi di artefatto possono essere dovuti a motivi fisiologici, si pensi all’effetto del respiro del paziente o alle irregolarità del segnale ECG in acquisizioni cardiache sincronizzate con l’ECG stesso. 

<img src="./images/image-29.png" alt="Esempi di artefatto" style="width:50%;">

*Figura 1.29. Esempi di artefatto.*

## Software per l'elaborazione di immagini biomediche

L’elaborazione delle immagini biomediche in ambito clinico deve avvenire, come prima descritto, attraverso software certificato. Esistono numerosi software commerciali, sia prodotti dalle case costruttrici dei dispositivi di acquisizione che da ditte indipendenti dalle stesse. Nel primo caso il software può essere integrato nella macchina di acquisizione (in questo caso la certificazione si opera sull’intera apparecchiatura) o “stand alone”, quindi installato su un computer (nel gergo dei sistemi PACS workstation). Nel secondo caso il software è necessariamente stand alone. 
Un software stand alone residente su di una workstation deve integrarsi con il sistema PACS su cui risiedono le immagini e quindi è tipicamente composto da una interfaccia di base che consente di scaricare o importare immagini in formato DICOM ed inserirle in un archivio interno. Da tale archivio le immagini possono essere estratte per l’elaborazione. I risultati dell’elaborazione vengono salvati sulla workstation. I software clinici sono tipicamente molto costosi (decine di migliaia di euro) e vengono di solito distribuiti con un sistema di licenze annuali che includono l’aggiornamento ed il supporto. 

Per scopi di ricerca o di studio sono disponibili vari software stand alone gratuiti (chiaramente non certificati) che possono essere utilizzati per l’archiviazione e l’elaborazione di immagini biomediche. 

Alcuni esempi sono:
1. imageJ (https://imagej.net/ij/index.html). E’ un software multipiattaforma (Open Source, Java) sviluppato dall’ NIH (National Institutes of Health, USA). E’ un software essenziale che permette di importare immagini in formato DICOM ed eseguire numerosi tipi di elaborazione. E’ completato da una collezione di plugins (https://imagej.nih.gov/ij/plugins/), cioè applicazioni sviluppate da utenti del software, che implementano vari algoritmi di elaborazione. Essendo il software open source, è possibile implementare nuovi plugins o modificare quelli esistenti.
2. MIPAV (https://mipav.cit.nih.gov/) E’ un software multipiattaforma (Java) sviluppato dall’ NIH (National Institutes of Health, USA).  E’ un software che permette di importare immagini in formato DICOM ed eseguire numerosi tipi di elaborazione maggiormente evoluto rispetto ad imageJ. Il software non è Open Source ma permette di sviluppare plugins integrabili con il MIPAV.
3. 3D Slicer (https://www.slicer.org/). E’ un software multipiattaforma (C++, Tcl/Tk). E’ un software che permette di importare immagini in formato DICOM ed eseguire numerosi tipi di elaborazione. Rispetto a imageJ e MIPAV permette di elaborare efficacemente dati di tipo volumetrico. Il software è Open Source e permette di sviluppare plugins. 
4. Horos (https://horosproject.org/). E’ un software free/open source solo su piattaforma MacOS che implementa la struttura di una vera e propria workstation radiologica, quindi permette di sperimentare un ambiente simile a quello dei prodotti clinici. E’ la versione free di Osirix (https://www.osirix-viewer.com/) che implementa una versione certificata ad uso clinico.

Esistono molti altri software che consentono la gestione di file DICOM e implementano algoritmi di elaborazione delle bioimmagini. Una lista è disponibile su https://idoimaging.com/.
L’elaborazione delle immagini biomediche può essere naturalmente eseguita sviluppando i propri algoritmi nei vari ambienti di programmazione. In questo corso utilizzeremo l’ambiente MATLAB, un ambiente commerciale che consente di importare immagini DICOM e di utilizzare su queste le varie funzioni di elaborazione disponibili. 
In alternativa è possibile utilizzare ambienti free come python (https://www.python.org/), o qualsiasi linguaggio di programmazione che possieda librerie per la gestione del formato DICOM. In python è anche disponibile lo strumento ParaView (https://www.paraview.org/), particolarmente utile nella gestione di mesh tridimensionali. In python sono sviluppati i principali ambienti per l’elaborazione di immagini biomediche attraverso reti neurali (CNN) come Keras e Pytorch.   


## Bibliografia
1. Constantinides CD, Atalar E, McVeigh ER. Signal-to-noise measurements in magnitude images from NMR phased arrays. Magnetic Resonance in Medicine 1997;38(5):852–857.
2. R Rangayyan, Biomedical Image Analysis, CRC Press 2004